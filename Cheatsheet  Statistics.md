<html>
<head>
  <title>Evernote Export</title>
  <basefont face="Arial" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="Evernote Windows/309198 (en-US, DDL); Windows/10.0.0 (Win64);"/>
  <style>
    body, td {
      font-family: Arial;
      font-size: 12pt;
    }
  </style>
</head>
<body>
<a name="141114"/>

<div><span><div><a href="evernote:///view/6367254/s57/f1dae14f-b0c0-4024-a6f5-7b2535f53308/67117fc9-036c-4028-b61e-04a2b3349d73/" rel="noopener noreferrer" rev="en_rl_none">ğŸ“ŒCheatsheet | Python (Anthony Sardelliti) programmation-python</a></div><div><br/></div><div><a href="https://asardell.github.io/statistique-python/">https://asardell.github.io/statistique-python/</a></div><div><br/></div><div><br/></div><div>MÃ©thode :Â </div><ul><li><div>Aller retour nettoyage et analyse</div></li><li><div>Valeurs manquantes :Â </div></li><ol><li><div>Trouver la bonne valeur (Ã  la main)</div></li><li><div>Travailler avec un gruyÃ¨re</div></li><li><div>Oublier la variable</div></li><li><div>Oublier les individus (mais les individus restants ne sont pas forcÃ©ment reprÃ©sentatifs)</div></li><li><div>Imputer (= deviner, e.g. imputation par la moyenne, ou imputer intelligemment, eg selon Ã¢ge pour la taille)</div></li></ol><li><div>Traiter les outliers (= valeur aberrantes)</div><div>trouvÃ©es par Z-score ou Ã©cart interquartile</div></li><ol><li><div>Trouver la bonne valeur (Ã  la main)</div></li><li><div>Supprimer la valeur ou conserver la valeur ... en fonction des Ã©tudes (e.g. moyenne vs mÃ©diane)</div></li><li><div>... les valeurs atypiques sont intÃ©ressantes, et Ã  mentionner</div></li></ol><li><div>Eliminer les doublons... si on peut</div></li><ul><li><div>Regrouper en gÃ©rant les contradictions</div></li></ul><li><div><br/></div></li></ul><div><br/></div><div><span style="font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;, &quot;Segoe UI Symbol&quot;;"><span style="font-size: 16px;"><span style="color:rgb(42, 49, 53);">MÃ©thodeÂ :</span></span></span></div><ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">MÃ©thodeÂ :</span></span></span></div></li><ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">AllerÂ retour nettoyage et analyse</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">ValeursÂ manquantes :</span></span></span></div></li><ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">TrouverÂ la bonne valeur (Ã  la main)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">TravaillerÂ avec un gruyÃ¨re</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">OublierÂ la variable</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">OublierÂ les individus (mais les individus restants ne sont pas forcÃ©ment reprÃ©sentatifs)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">ImputerÂ (= deviner, e.g. imputation par la moyenne, ou imputer intelligemment, eg selon Ã¢ge pour la taille)</span></span></span></div></li></ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">TraiterÂ les outliers (= valeur aberrantes)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">trouvÃ©esÂ par Z-score ou Ã©cart interquartile</span></span></span></div></li><ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">TrouverÂ la bonne valeur (Ã  la main)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">SupprimerÂ la valeur ou conserver la valeur ... en fonction des Ã©tudes (e.g. moyenne vs mÃ©diane)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">...Â les valeurs atypiques sont intÃ©ressantes, et Ã  mentionner</span></span></span></div></li></ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">EliminerÂ les doublons... si on peut</span></span></span></div></li><ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">RegrouperÂ en gÃ©rant les contradictions</span></span></span></div></li></ul></ul></ul><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 16px;"><span style="color:rgb(51, 51, 51);">MÃ©thodeÂ :</span></span></span></div><ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">AllerÂ retour nettoyage et analyse</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">ValeursÂ manquantes :</span></span></span></div></li><ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">TrouverÂ la bonne valeur (Ã  la main)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">TravaillerÂ avec un gruyÃ¨re</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">OublierÂ la variable</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">OublierÂ les individus (mais les individus restants ne sont pas forcÃ©ment reprÃ©sentatifs)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">ImputerÂ (= deviner, e.g. imputation par la moyenne, ou imputer intelligemment, eg selon Ã¢ge pour la taille)</span></span></span></div></li></ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">TraiterÂ les outliers (= valeur aberrantes)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">trouvÃ©esÂ par Z-score ou Ã©cart interquartile</span></span></span></div></li><ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">TrouverÂ la bonne valeur (Ã  la main)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">SupprimerÂ la valeur ou conserver la valeur ... en fonction des Ã©tudes (e.g. moyenne vs mÃ©diane)</span></span></span></div></li><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">...Â les valeurs atypiques sont intÃ©ressantes, et Ã  mentionner</span></span></span></div></li></ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">EliminerÂ les doublons... si on peut</span></span></span></div></li><ul><li><div><span style="font-family: &quot;Helvetica Neue&quot;, Arial, sans-serif;"><span style="font-size: 13px;"><span style="color:rgb(51, 51, 51);">RegrouperÂ en gÃ©rant les contradictions</span></span></span></div></li></ul></ul><div>Vocabulaire :Â </div><ul><li><div>Stat descriptives</div></li><li><div>probabilitÃ©s = statistique infÃ©rentielle</div></li><ul><li><div>tests satistiques, estimateurs</div></li></ul><li><div>individus =&gt; observation, reÃ¡lisation</div></li><li><div>variables, population, Ã©chantillon, jeu de donnÃ©es</div></li></ul><img src="ğŸ“ŒCheatsheet  Statistics_files/Image.jpg" type="image/jpeg" data-filename="Image.jpg" style="--en-naturalWidth:843; --en-naturalHeight:329;" width="513px"/><ul><li><div>variables discrÃ¨tes, continues</div></li><ul><li><div>Noir = nominal, ordinal, interval (cardinal), ratio</div></li></ul><li><div>variables qualitatives =&gt; modalitÃ©s</div></li><ul><li><div>nominale</div></li><li><div>ordinale ( e.g. dates)</div></li><li><div>boolÃ©enne</div></li></ul><li><div>7 types d'erreurs :Â </div></li><ol><li><div>Valeurs manquantes</div></li><li><div>erreur lexicale (e.g. nombre lÃ  oÃ¹ chiffre attendu, ou liste limitative de pays possibles,,)</div></li><li><div>IrrÃ©gularitÃ© (e.g. unite de mesure diffÃ©rente)</div></li><li><div>??? supposition clef unique (e.g. 2 emails pour 1 personne)</div></li><li><div>formatage</div></li><li><div>doublon (+ parfois contradiction)</div></li><li><div>valeur extrÃªme = <b>atypique ou aberrante</b> (outlier)</div></li></ol></ul><div><br/></div><ol><li><div>Deviner une valeur manquante = <b>imputation</b></div></li></ol><div>e.g. imputation par la moyenne (simple) -&gt; mÃ©thode de hot-deck, Machine Learning, rÃ©gressions</div><ol start="6"><li><div>Doublon =&gt; mÃ©thode duplicated()</div></li><li><div>Valeur extrÃªmeÂ  = midspread ou Z-score, ou boite a moustache</div></li></ol><hr/><div>ReprÃ©senter des variables</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><hr/><div><br/></div><div>SupervisÃ© =&gt; j'ai dÃ©ja des tag d'apprentissage. On parle de <b>classement</b>= classification supervisÃ©e (en EN = &quot;classification&quot;).Â </div><div>Non supervisÃ© =Â  <b>clusteringÂ </b></div><img src="ğŸ“ŒCheatsheet  Statistics_files/Image.png" type="image/png" data-filename="Image.png" style="--en-naturalWidth:413; --en-naturalHeight:150;"/><div><br/></div><div>D</div><hr/><div>Distance (erreur = risque = eloignement des donnÃ©es vs prediction modele)</div><div>Attention : erreur = risque empirique != performance du modele</div><ul><li><div>erreur quadratique (le + utilisÃ©)</div></li><ul><li><div>distance euclidienne = sqr(x^2 + y^2)</div></li></ul><li><div>Distance manhattan = x + y</div></li><li><div>Pour chaines de caracteres = distance de <span style="--en-highlight:yellow;background-color: #ffef9e;">Levenshtein</span> = nbre mini d'operation (substitution, insertion, suppression) pour passer de l'une a l'autre.Â </div></li><ul style="--en-todo:true;"><li style="--en-checked:false;"><div>a connaitre = algo de Wagner et Fischer pour le calcul de la distance de Levenshtein.</div></li></ul></ul><div>algo paramÃ©triques (eg regression = droite) =&gt; on cherche le parametreÂ <span style="font-size: 16px;"><span style="color:rgba(0, 0, 0, 0.92);">Î¸ (qui peut etre multidimensionel)</span></span></div><div>algos non parametriques (+ complexitÃ©) =&gt; egg k-means qui est 'memory based' (garde toutes les donnÃ©es en memoire)</div><div><br/></div><div><br/></div><div><br/></div><div>fuction loss = perte d'information</div><div>vraisemblance d'un jeu d'observations (x1...xN) par rapport Ã  un modÃ¨le en statistiques est la fonction suivante :Â Â L(Î¸)=p(x1...xN|Î¸)Â Â .= proba d'avoir x1...xN sachant \Theta</div><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">Â </span></span><span style="font-size: 16px;"><span style="color:rgba(0, 0, 0, 0.92);">Î¸^</span></span><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">Â avec un accent circonflexeÂ lorsqu'on parle d'unÂ estimateur (eet non de la valeur reelle, intrinseque)</span></span></div><div><br/></div><hr/><ol><li><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">MÃ©thode factorielle = la + connue ACP</span></span></div></li><li><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">Clulstering = Classification non supervisÃ©e = la + connue k-means (K-moyennes)</span></span></div></li></ol><div><br/></div><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">Factorielle :Â </span></span></div><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">ACPÂ  ( = EN PCA) = Principal component analysis</span></span></div><ul><li><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">Â  Â  recehche d'un (hyperplan) avec moment d'inertie max (Ã©talement des points) = axe orthogonal Ã  l'hyperplan = donne indication sur la variabilitÃ© =</span></span></div></li><ul><li><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">espace Rp de dimension p variables, contient Ni le nuage des individus</span></span></div></li></ul><li><div><span style="color:rgba(0, 0, 0, 0.92);">Rechreche des corrÃ©lations entre variablesÂ </span></div></li><ul><li><div><span style="color:rgba(0, 0, 0, 0.92);">espace Rn de dimension n individus, contient Np le nuage des variables</span></div></li></ul></ul><div><span style="color:rgba(0, 0, 0, 0.92);">De prÃ©fÃ©rence ACP normÃ©e (centrÃ©e rÃ©duite)</span></div><div><span style="color:rgba(0, 0, 0, 0.92);">3 graphiques :Â </span></div><ol><li><div><span style="color:rgba(0, 0, 0, 0.92);">1. Pour l'objectif 1, ce sera la projection du nuage des individus NI sur les 2 premiers axes dâ€™inertie, câ€™est-Ã -dire sur le premier plan factoriel.</span></div></li><li><div>Le second sâ€™appelle le cercle des corrÃ©lations.</div></li><li><div><span style="color:rgba(0, 0, 0, 0.92);">2. Pour l'objectif 2, ce sera la projection du nuage des variables NK sur le premier plan factoriel.</span></div></li></ol><div><br/></div><div><span style="font-size: 1rem;">combien de composantes = min (p nbr de varialbes et n-1 nombre individus)</span></div><div><span style="font-size: 1rem;">=&gt; eboulis des valeurs propres (classÃ©es en valeur dÃ©croissante)</span></div><div><span style="font-size: 1rem;">=&gt; frequent de n'analyser que le 1er plan (2 composantes). Critere du coude - reperer le # oÃ¹ le % inertie diminue + lentement. Criter de Kaiser (~contribution moyenen 100% / p)</span></div><div><br/></div><div><span style="color:rgba(0, 0, 0, 0.92);">k-meansÂ </span></div><div><span style="color:rgba(0, 0, 0, 0.92);">k est un</span> <b><span style="color:rgba(0, 0, 0, 0.92);">hyperparamÃ¨tre</span></b> <span style="color:rgba(0, 0, 0, 0.92);">(c'est Ã  nous de l'optimiser, ce n'est pas l'algo qui va le proposer).Â </span></div><div><br/></div><div><br/></div><div>Trainig set vs testing set = 80% / 20% des donnÃ©es fournies</div><div><br/></div><div><br/></div><hr/><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">Conversion de timestamp unix =Â Â </span><a href="http://www.epochconverter.com/" rev="en_rl_none"><span style="color:rgb(116, 81, 235);"><u>www.epochconverter.com</u></span></a><span style="color:rgba(0, 0, 0, 0.92);">Â !</span></span></div><div><br/></div><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">Erreur lexicale =&gt; Technique du dictionnaire.</span></span></div><div><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">Date =&gt; Format normalisÃ© ISO8601Â </span></span><span style="font-family: monospace, monospace;"><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">1977-04-22T06:00:00Z</span></span></span><span style="font-size: 1rem;"><span style="color:rgba(0, 0, 0, 0.92);">.</span></span></div><div><br/></div><div><br/></div><div><br/></div><hr/><div><br/></div><div><b><span style="font-size: 20px;">Comment centrer reduire : </span></b></div><div style="--en-codeblock:true;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div>import pandas as pd</div><div>import numpy as np</div><div>from sklearn.preprocessing import StandardScaler</div></div><div>DÃ©finissons nos donnÃ©es :</div><div><br/></div><div style="--en-codeblock:true;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div># Notre matrice de base : </div><div>X = [[12,Â  Â  30,Â  Â  80,Â  -100],Â  Â   [-1000, 12,Â  Â  -23,Â  10],Â  Â   [14,Â  Â  1000,Â  0,Â  Â  0]]</div><div><br/></div><div># Version numpy : </div><div>X = np.asarray(X)</div><div># Version pandas : </div><div>X = pd.DataFrame(X)</div></div><div>Avec Â pandasÂ  , on peut calculer la moyenne et l'Ã©cart-type de chaque dimensionÂ :</div><div><br/></div><div style="--en-codeblock:true;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div># On applique la methode .describe() pour avoir la moyenne et la .std(), et la mÃ©thode .round(2) pour arrondir Ã  2 dÃ©cimales aprÃ¨s la virgule : </div><div>X.describe()</div></div><div>On peut ensuite Â«Â scalerÂ Â» nos donnÃ©es :</div><div><br/></div><div style="--en-codeblock:true;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial;"><div># On instancie notre scaler : </div><div>scaler = StandardScaler()</div><div># On le fit : </div><div>scaler.fit(X)</div><div># On l'entraine : </div><div>X_scaled = scaler.transform(X)</div><div># On peut faire les 2 opÃ©rations en une ligne : </div><div>X_scaled = scaler.fit_transform(X)</div><div># On le transforme en DataFrame : </div><div>X_scaled = pd.DataFrame(X_scaled)</div><div># On peut appliquer la mÃ©thode .describe() et .round()</div><div>X_scaled.describe().round(2)</div></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><hr/><div><br/></div><div><br/></div></span>
</div></body></html> 